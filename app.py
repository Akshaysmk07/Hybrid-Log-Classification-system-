import streamlit as st
from dotenv import load_dotenv
import pandas as pd
import joblib  # For loading a trained model (if you have one)
from streamlit_option_menu import option_menu

from processor_regex import classify_with_regex
from processor_bert import classify_with_bert
from processor_llm import classify_with_llm
import os

# # Get the PORT from the environment variable
# port = int(os.getenv("PORT", 8501))
# Set page title and layout

load_dotenv()
st.set_page_config(page_title="Log Classification System", layout="wide")
st.markdown("""
    <style>
        h1, h2, h3 {
            color: orange !important;
        }
    </style>
""", unsafe_allow_html=True)

# Sidebar with navigation menu
with st.sidebar:
    selected = option_menu(
        menu_title="Main Menu",  
        options=["About Project", "log classifier page" ],  
        icons=["person", "tools"],  
        menu_icon="clipboard",  
        default_index=0  
    )

if selected == "About Project":
    st.markdown("""
    <style>
        h1, h2, h3 {color: orange;}
    </style>
    """, unsafe_allow_html=True)
    st.markdown("""
    # Log Classification With Hybrid Classification Framework

    This project implements a hybrid log classification system, combining three complementary approaches to handle varying levels of complexity in log patterns. The classification methods ensure flexibility and effectiveness in processing predictable, complex, and poorly-labeled data patterns.

    ---

    ## Classification Approaches

    1. **Regular Expression (Regex)**:
       - Handles the most simplified and predictable patterns.
       - Useful for patterns that are easily captured using predefined rules.

    2. **Sentence Transformer + Logistic Regression**:
       - Manages complex patterns when there is sufficient training data.
       - Utilizes embeddings generated by Sentence Transformers and applies Logistic Regression as the classification layer.

    3. **LLM (Large Language Models)**:
       - Used for handling complex patterns when sufficient labeled training data is not available.
       - Provides a fallback or complementary approach to the other methods.
    """)

    # Correct way to load image in Streamlit
    st.image("resources/arch.png", caption="System Architecture", use_column_width=True)

    st.markdown("""
    ---

    ## Folder Structure

    - **`training/`**: Code for training models using Sentence Transformer and Logistic Regression, including regex-based classification.
    - **`models/`**: Stores trained models like Sentence Transformer embeddings and the Logistic Regression model.
    - **`resources/`**: Contains resource files such as test CSV files, output files, images, etc.
    - **Root Directory**: Contains the FastAPI server code (`server.py`).

    ---

    ## Setup Instructions

    1. **Install Dependencies**:
       ```bash
       pip install -r requirements.txt
       ```

    2. **Run the FastAPI Server**:
       ```bash
       uvicorn server:app --reload
       ```

       Once the server is running, access the API at:
       - [`http://127.0.0.1:8000/`](http://127.0.0.1:8000/) (Main endpoint)
       - [`http://127.0.0.1:8000/docs`](http://127.0.0.1:8000/docs) (Swagger documentation)
       - [`http://127.0.0.1:8000/redoc`](http://127.0.0.1:8000/redoc) (Alternative API documentation)

    ---

    ## Usage

    Upload a CSV file containing logs to the FastAPI endpoint for classification. Ensure the file has the following columns:
    - `source`
    - `log_message`

    The output will be a CSV file with an additional column `target_label`, representing the classified label for each log entry.
    """)


elif selected == "log classifier page":
    # Custom styling
    st.markdown("""
        <style>
            .main {text-align: center;}
            h1 {color: #4CAF50; text-align: center;}
            .stButton button {width: 100%;}
            .instructions {
                background-color: #0000;
                padding: 15px;
                border-radius: 10px;
                box-shadow: 2px 2px 10px rgba(0, 0, 0, 0.1);
                font-size: 16px;
                text-align: left;
            }
        </style>
    """, unsafe_allow_html=True)

    # Title
    st.title("Log Classification System")

    # Description
    st.markdown("""
    <div class="instructions">
        <h3>Instructions:</h3>
        <ul>
            <li>üìÇ <b>Upload</b> a CSV file containing log data.</li>
            <li>üîç The dataset should have at least two columns: <b>source</b> and <b>log_message</b>.</li>
            <li>üöÄ Click the <b>Predict</b> button to classify the logs.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    # Upload CSV file
    uploaded_file = st.file_uploader("Upload a CSV Log File", type=["csv"])

    def classify(logs):
        labels = []
        for source, log_msg in logs:
            label = classify_log(source, log_msg)
            labels.append(label)
        return labels

    def classify_log(source, log_msg):
        if source == "LegacyCRM":
            label = classify_with_llm(log_msg)
        else:
            label = classify_with_regex(log_msg)
            if not label:
                label = classify_with_bert(log_msg)
        return label

    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.write("### Uploaded Data Preview")
        st.dataframe(df.head())
        
        if st.button("Predict"):
            df["Prediction"] = classify(list(zip(df["source"], df["log_message"])))
            st.write("### Classification Results")
            st.dataframe(df)
            
            # Download button for results
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button("Download Predictions", data=csv, file_name="log_predictions.csv", mime="text/csv")


    
# if __name__ == "__main__":
#     import subprocess
#     subprocess.run(["streamlit", "run", "app.py", "--server.port", str(port), "--server.address", "0.0.0.0"])